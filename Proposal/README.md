## View-Only Overleaf:
[https://www.overleaf.com/read/vnwtsmftphsn#f37ae3](https://www.overleaf.com/read/vnwtsmftphsn#f37ae3)

![Black White and Gray Monochromatic Simplicity Landscape University Research Poster](https://github.com/Rising-Stars-by-Sunshine/CSECON206_Polina_Final_Project/assets/148934457/7f5f4191-9be9-4b05-add0-40b0fdaa1052)


## Background/Motivation:

In response to the influence of artificial intelligence (AI) in contemporary society, the U.S. government has proposed a "Blueprint for an AI Bill of Rights," emphasizing the imperative of protecting individuals from algorithmic discrimination and ensuring equitable AI design and usage. Central to this discourse is the pressing need to scrutinize the inherent biases within AI systems, a task our study undertakes by focusing on the widely deployed ChatGPT 3.5 model. With a particular lens on age and gender influences, our research delves into how contextual factors shape the decision-making processes of AI agents, aiming to illuminate the intricacies of algorithmic biases and pave the way for more equitable and transparent AI technologies. The study focuses on the Prisoner's Dilemma, as it provides a distinctive framework to investigate these biases, in part because of its fundamental nature in comprehending cooperation and decision-making in various fields. Through thorough experimentation and analysis, our goal is to illuminate how age and gender dynamics impact the decisions made by AI agents, unveiling the intricacies embedded in algorithmic decision-making.

## Research Questions:

How do age and gender influence decision-making in AI agents within the context of the Prisonerâ€™s Dilemma game?
What implications do these findings have for the development and deployment of AI systems in real-world scenarios?

These questions are important because they address the fundamental challenges posed by the integration of AI into strategic decision-making processes, particularly in the context of government project allocation. Existing game theory literature may not fully account for the complexities introduced by AI agents' adaptive behavior and learning mechanisms.

## Application Scenario:

The application of this research lies in advancing our understanding of algorithmic decision-making within artificial intelligence systems, particularly in relation to biases influenced by factors such as age and gender. Practically, the insights garnered from this research can inform the development of more equitable and transparent AI technologies. For instance, by identifying and mitigating biases within AI models like ChatGPT 3.5, developers and policymakers can work towards ensuring fairer outcomes in various applications such as customer service chatbots, recommendation systems, and decision support tools.

Moreover, understanding the nuances of algorithmic bias can lead to the formulation of guidelines and regulations, as well as the implementation of safeguards, aimed at promoting responsible AI deployment across different sectors of society.

## Methodology:

The study employs a combination of quantitative analysis and qualitative assessment to examine the decision-making processes of ChatGPT 3.5 within the Prisoner's Dilemma framework. Quantitative data will be collected on the decisions made by ChatGPT 3.5 in each scenario, including the choices selected and the reasoning provided. 

- Experimental Design
- Data Collection
- Data Analysis
- Ethical Considerations

## Preliminary Results:

Given 4 possible outcomes:

If Player 1 stays silent and Player 2 confesses, Player 1 gets the worst outcome (10 years) while Player 2 goes free (0 years). 
If Player 2 stays silent and Player 1 confesses, Player 2 gets the worst outcome (10 years) while Player 1 goes free (0 years). 
If they both confess, they both end up with a moderate outcome (5 years). 
If they both stay silent, they both get a better outcome (1 year).

There has been an observed discrepancy between different strategies that are influenced by age/sex. 

To further enhance the current research, the analysis will greatly benefit from carrying out games where both factors are introduced simultaneously (age + sex) to see if any further results will differ from the current findings, as well as running the games 10+ times to see the extent of the randomized factor's influence.

## Intellectual Merits and Practical Impacts:

The intellectual merits of this research lie in its interdisciplinary approach to understanding and addressing algorithmic biases within artificial intelligence systems. By leveraging the Prisoner's Dilemma framework, the study not only advances our theoretical understanding of cooperative decision-making but also offers novel insights into the complexities of AI decision-making processes influenced by factors like age and gender dynamics. As the research is conducted as an extention of an existing research by Mei et. al, the research opens up a larger area of AI equity and fairness testing for the future researches and the extensions of this research.
